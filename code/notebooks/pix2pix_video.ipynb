{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Hyperparameters (Put here for now. Probably should find a way to organize them)\n",
    "SIZE = 256\n",
    "INPUT_CHANNELS = 3\n",
    "OUTPUT_CHANNELS = 3\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "BETA1 = 0.5 # Beta1 hyperparam for Adam optimizers\n",
    "SHUFFLE = True\n",
    "\n",
    "\n",
    "class NeuralModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load in default parameters\n",
    "        self.size = SIZE\n",
    "        self.input_c = INPUT_CHANNELS\n",
    "        self.output_c = OUTPUT_CHANNELS\n",
    "        self.num_epochs = NUM_EPOCHS\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.lr = LEARNING_RATE\n",
    "        self.beta1 = BETA1\n",
    "        self.shuffle = SHUFFLE\n",
    "\n",
    "        current_time = datetime.datetime.now() - datetime.timedelta(hours=8)\n",
    "        print(\"Starting at:\", current_time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "\n",
    "    def forward(self, obs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prepare_batch(self, data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "import functools\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_DOWNS = 8\n",
    "NGF = 64\n",
    "LAMBDA_L1 = 100\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.y is None:\n",
    "            return self.x[index]\n",
    "        else:\n",
    "            return self.x[index], self.y[index]\n",
    "\n",
    "\n",
    "# Reference: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/\n",
    "class Pix2PixUnet(NeuralModel, nn.Module):\n",
    "    \"\"\"Create a Unet-based generator\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Construct a Unet generator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            output_nc (int) -- the number of channels in output images\n",
    "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
    "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
    "            ngf (int)       -- the number of filters in the last conv layer\n",
    "            norm_layer      -- normalization layer\n",
    "        We construct the U-Net from the innermost layer to the outermost layer.\n",
    "        It is a recursive process.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # hyper params\n",
    "        self.num_downs = NUM_DOWNS\n",
    "        self.ngf = NGF\n",
    "        self.lambda_L1 = LAMBDA_L1\n",
    "        self.norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(self.ngf * 8, self.ngf * 8, input_nc=None, submodule=None, norm_layer=self.norm_layer, innermost=True)  # add the innermost layer\n",
    "        for i in range(self.num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
    "            unet_block = UnetSkipConnectionBlock(self.ngf * 8, self.ngf * 8, input_nc=None, submodule=unet_block, norm_layer=self.norm_layer, use_dropout=False)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(self.ngf * 4, self.ngf * 8, input_nc=None, submodule=unet_block, norm_layer=self.norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(self.ngf * 2, self.ngf * 4, input_nc=None, submodule=unet_block, norm_layer=self.norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(self.ngf, self.ngf * 2, input_nc=None, submodule=unet_block, norm_layer=self.norm_layer)\n",
    "        self.model = UnetSkipConnectionBlock(self.output_c, self.ngf, input_nc=self.input_c, submodule=unet_block, outermost=True, norm_layer=self.norm_layer)  # add the outermost layer\n",
    "        \n",
    "        \n",
    "        self.device = torch.device(\n",
    "            f\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "    \n",
    "        print(f\"Device: {self.device}\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.beta1, 0.999))\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.criterionL1 = torch.nn.L1Loss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # load data from file\n",
    "        with h5py.File(\"data_950_0to1.h5\", 'r') as hf:\n",
    "            data_x = hf['x'][:]\n",
    "            data_y = hf['y'][:]\n",
    "\n",
    "        # 80/20 split\n",
    "        # data_tr, data_te = data_obs.split()\n",
    "        train_ind = int(len(data_x) * 0.8)\n",
    "        data_tr = Dataset(data_x[:train_ind], data_y[:train_ind])\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            data_tr,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle\n",
    "        )\n",
    "        \n",
    "        train_losses = []\n",
    "        loss_gen_list = []\n",
    "        loss_L1_list = []\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            start_time1 = time.time()\n",
    "\n",
    "            epoch_loss = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                start_time2 = time.time()\n",
    "\n",
    "                data, target = batch\n",
    "\n",
    "                outputs = self.model(data.float().to(self.device))\n",
    "                \n",
    "                # if you want to see the progress of the outputs\n",
    "#                 if batch_idx % 20 == 0:\n",
    "#                     out = outputs.detach().cpu().numpy()\n",
    "#                     tar = target.detach().cpu().numpy()\n",
    "#                     plt.subplot(1, 2, 1)\n",
    "#                     plt.imshow(out.transpose((0, 2, 3, 1))[0])\n",
    "#                     plt.subplot(1, 2, 2)\n",
    "#                     plt.imshow(tar.transpose((0, 2, 3, 1))[0])\n",
    "#                     plt.show()\n",
    "\n",
    "                loss_gen = self.criterion(outputs, target.float().to(self.device))\n",
    "                #loss_gen = 0\n",
    "                loss_L1 = self.criterionL1(outputs, target.float().to(self.device)) * self.lambda_L1\n",
    "                loss = loss_gen + loss_L1\n",
    "                \n",
    "                loss_gen_list.append(loss_gen)\n",
    "                loss_L1_list.append(loss_L1)\n",
    "                \n",
    "                # Aggregate loss across mini-batches (per epoch)\n",
    "                epoch_loss += loss\n",
    "\n",
    "                # Backprop and perform Adam optimisation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if batch_idx % 38 == 0:\n",
    "                    print(\n",
    "                    f\"Epoch: {epoch}\\tBatch: {batch_idx}\\tGen Loss: {loss_gen:.5f}\\tL1 Loss: {loss_L1:.5f}\"\n",
    "                    f\"\\tTotal Time: {(time.time() - start_time2)/60:.3f} minutes\"\n",
    "                    )\n",
    "\n",
    "            print(\n",
    "                f\"Epoch: {epoch}\\tTrain Loss: {epoch_loss/len(train_loader):.5f}\"\n",
    "                f\"\\tTotal Time: {(time.time() - start_time1)/60:.3f} minutes\"\n",
    "            )\n",
    "\n",
    "            train_losses.append(epoch_loss / len(train_loader))\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, figsize=(15,15))\n",
    "        fig.suptitle(\"Loss Plots\")\n",
    "        ax1.plot(range(len(loss_gen_list)), loss_gen_list, alpha = 0.7)\n",
    "        ax1.set_title(\"Gen Loss\")\n",
    "        ax2.plot(range(len(loss_gen_list)), loss_L1_list, alpha = 0.7)\n",
    "        ax2.set_title(\"L1 Loss\")\n",
    "        plt.show()\n",
    "        \n",
    "        return train_losses\n",
    "    \n",
    "    def predict(self):\n",
    "        self.shuffle = False\n",
    "        \n",
    "        # load data from file\n",
    "        with h5py.File(\"data_950_0to1.h5\", 'r') as hf:\n",
    "            data_x = hf['x'][:]\n",
    "            data_y = hf['y'][:]\n",
    "        \n",
    "        color_distance = []\n",
    "        outputImgs = []\n",
    "        \n",
    "        # 80/20 split\n",
    "        # data_tr, data_te = data_obs.split()\n",
    "        train_ind = int(len(data_x) * 0.8)\n",
    "        #data_te = Dataset(data_x[train_ind:], data_y[train_ind:])\n",
    "        data_te = Dataset(framesList, framesList)\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            data_te,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle\n",
    "        )\n",
    "        \n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            start_time2 = time.time()\n",
    "            #print(batch)\n",
    "            data, target = batch\n",
    "            x = data.detach().cpu().numpy().transpose((0, 2, 3, 1))[0]\n",
    "            y = target.detach().cpu().numpy().transpose((0, 2, 3, 1))[0]\n",
    "            \n",
    "            outputs = self.model(data.float().to(self.device))\n",
    "            \n",
    "            y_hat = outputs.detach().cpu().numpy().transpose((0, 2, 3, 1))[0]\n",
    "            \n",
    "            dist = 0\n",
    "            for i in range(0, len(y)):\n",
    "                for j in range(0,len(y[i])):\n",
    "                    dist += np.sqrt((y[i][j][0] - y_hat[i][j][0])**2 + (y[i][j][1] - y_hat[i][j][1])**2 +\n",
    "                                      (y[i][j][2] - y_hat[i][j][2])**2)\n",
    "            dist = dist/len(y)\n",
    "            color_distance.append(dist)\n",
    "\n",
    "            if True:\n",
    "                '''\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(16, 5))\n",
    "                ax[0].axis('off')\n",
    "                ax[0].set_title('$X$')\n",
    "                ax[0].imshow(x)\n",
    "                ax[1].axis('off')\n",
    "                ax[1].set_title('$\\hat{Y}$')\n",
    "                ax[1].imshow(y_hat)\n",
    "                ax[2].axis('off')\n",
    "                ax[2].set_title('$Y$')\n",
    "                ax[2].imshow(y)   \n",
    "                plt.show()\n",
    "                '''\n",
    "                \n",
    "                plt.imshow(y_hat)\n",
    "                #plt.savefig(\"data/MCFrame%d.png\" % batch_idx)\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"Color difference: %d\" % (dist))\n",
    "                \n",
    "            outputImgs.append(y_hat)\n",
    "            \n",
    "        print(\"Average color difference: %d\" % (np.mean(np.array(color_distance))))\n",
    "        print(\"Max color difference: %d\" % (max(color_distance)))\n",
    "        print(\"Min color difference: %d\" % (min(color_distance)))\n",
    "        \n",
    "        print(color_distance)\n",
    "        return outputImgs\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    \"\"\"Defines the Unet submodule with skip connection.\n",
    "        X -------------------identity----------------------\n",
    "        |-- downsampling -- |submodule| -- upsampling --|\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        \"\"\"Construct a Unet submodule with skip connections.\n",
    "        Parameters:\n",
    "            outer_nc (int) -- the number of filters in the outer conv layer\n",
    "            inner_nc (int) -- the number of filters in the inner conv layer\n",
    "            input_nc (int) -- the number of channels in input images/features\n",
    "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
    "            outermost (bool)    -- if this module is the outermost module\n",
    "            innermost (bool)    -- if this module is the innermost module\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "        \"\"\"\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:   # add skip connections\n",
    "            return torch.cat([x, self.model(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Pix2PixUnet()\n",
    "\n",
    "tr_losses = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(img, size):\n",
    "    #img = cv2.imread(filename)\n",
    "    if img.shape[1] > img.shape[0]:\n",
    "        start_y = int(img.shape[1]/2 - img.shape[0]/2)\n",
    "        end_y = start_y + img.shape[0]\n",
    "        crop = img[0:img.shape[0], start_y:end_y]\n",
    "    else: \n",
    "        start_x = int(img.shape[0]/2 - img.shape[1]/2)\n",
    "        end_x = start_x + img.shape[1]\n",
    "        crop = img[start_x:end_x, 0:img.shape[1]]\n",
    "    return cv2.resize(crop, (size, size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vidcap = cv2.VideoCapture('data/MinecraftFootage1.mp4')\n",
    "success,image = vidcap.read()\n",
    "framesList = []\n",
    "count = 0\n",
    "while True:\n",
    "    #count += 1\n",
    "    #cv2.imwrite(\"data/frame%d.jpg\" % count, image)     # save frame as JPEG file     \n",
    "    success,image = vidcap.read()\n",
    "    if not success: break\n",
    "    #if count%2 != 0: continue\n",
    "    image = crop_and_resize(image, 256)\n",
    "    image[:,:,[2,0]] = image[:,:,[0,2]] #convert to RGB\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = image/255\n",
    "    framesList.append(image)\n",
    "\n",
    "framesList = np.asarray(framesList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(framesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.predict()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "for i in range(0,270):\n",
    "    #imgs.append(cv2.cvtColor(cv2.imread(\"data/MCFrame%d.png\" % i, 1), cv2.COLOR_BGR2RGB))\n",
    "    imgs.append(cv2.imread(\"data/MCFrame%d.png\" % i, 1))\n",
    "\n",
    "imgs = np.asarray(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results[170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results[170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((results[170]/2.0)+0.5, vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(results[170])[:,:,[2,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in results:\n",
    "    each /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results[130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "time = time.replace(':','-')\n",
    "cv2out = cv2.VideoWriter('data/footageTestDirect'+time+'.mp4',cv2.VideoWriter_fourcc('m','p','4','v'), 12, (256,256))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    cv2out.write((np.abs(results)[i]*255).astype('uint8')[:,:,[2,1,0]])\n",
    "    print(i)\n",
    "cv2out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vidcap = cv2.VideoCapture('data/MinecraftFootage1.mp4')\n",
    "success,image = vidcap.read()\n",
    "framesListNEW = []\n",
    "count = 0\n",
    "while count<100:\n",
    "    count += 1\n",
    "    #cv2.imwrite(\"data/frame%d.jpg\" % count, image)     # save frame as JPEG file     \n",
    "    success,image = vidcap.read()\n",
    "    if not success: break\n",
    "    #if count%2 != 0: continue\n",
    "    image = crop_and_resize(image, 256)\n",
    "    #image[:,:,[2,0]] = image[:,:,[0,2]] #convert to RGB\n",
    "    #image = np.transpose(image, (2, 0, 1))\n",
    "    #image = image/255\n",
    "    framesListNEW.append(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(framesListNEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(framesListNEW[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2out = cv2.VideoWriter('data/OriginalFootageCropped.mp4',cv2.VideoWriter_fourcc('m','p','4','v'), 60, (256,256))\n",
    "for f in framesList:\n",
    "    cv2out.write(f)\n",
    "cv2out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
